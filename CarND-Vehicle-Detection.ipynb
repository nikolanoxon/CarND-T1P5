{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection Project\n",
    "The goals / steps of this project are the following:\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "    - Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "    - Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Qt4Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "bins_range = (0, 256) # Range of histogram bins, should be (0,1) for .png and (0,256) for .jpg\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "max_center_offset = 100 # Allowable search range for a new vehicle\n",
    "max_frame_hist = 7 # Number of frames to average the vehicle history over\n",
    "max_loss_count = 3 # Number of allowed missing frames before the vehicle is considered lost\n",
    "min_lifetime = 3 # Number of consecutive frames needed to see vehicle\n",
    "# Search windows and scale\n",
    "ystart = [400, 400, 400, 400]\n",
    "ystop = [464, 496, 512, 628]\n",
    "scale = [1.0, 1.5, 1.75, 2.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_color(img, color_space):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else:\n",
    "        feature_image = np.copy(img)\n",
    "    return feature_image\n",
    "\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_image = convert_color(image, color_space)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "    \n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, color_space, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    bboxes = []\n",
    "\n",
    "    # Scale image to 0-1\n",
    "    if np.amax(img) > 1:\n",
    "        img = img.astype(np.float32)/255\n",
    "    \n",
    "    # Mask search area and convert color space \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, color_space)\n",
    "\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "    return bboxes\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def find_heatmap(image):\n",
    "    box_list = []\n",
    "    # Search through the image for cars\n",
    "    for search in zip(ystart, ystop, scale):\n",
    "        bboxes = find_cars(image, search[0], search[1], search[2], svc, X_scaler, color_space, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        box_list += bboxes\n",
    "        \n",
    "    # Read in image similar to one shown above \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    car_IDs = np.copy(range(0, labels[1]))\n",
    "\n",
    "    return heatmap, labels, car_IDs\n",
    "    \n",
    "def convert_heatmap_to_bbox(img,labels,car_IDs):\n",
    "    bbox = []\n",
    "    bbox_center = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in car_IDs:\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == (car_number+1)).nonzero()\n",
    "        \n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Define bounding boxes based on min/max x and y\n",
    "        bbox.append(((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy))))\n",
    "        bbox_center.append(((np.max(nonzerox)+np.min(nonzerox))/2,(np.max(nonzeroy) + np.min(nonzeroy))/2))\n",
    "    \n",
    "    return bbox, bbox_center\n",
    "\n",
    "def find_existing_targets(bbox, bbox_center, car_IDs):\n",
    "    # Find the most recent bounding box for each existing target\n",
    "    for target in targets:\n",
    "        offset = np.zeros_like(car_IDs)\n",
    "        # Check if a target already exists\n",
    "        if target.lifetime > 0:\n",
    "            # Find the distance from each bounding box to the vehicle\n",
    "            for car_index, car_number in enumerate(car_IDs):\n",
    "                if car_number != 99:\n",
    "                    offset[car_index] = np.linalg.norm(np.asarray(target.center) - np.asarray(bbox_center[car_index]))\n",
    "                else:\n",
    "                    offset[car_index] = max_center_offset\n",
    "\n",
    "            # If the closest box is within bounds, then a new box has been found this frame for this vehicle\n",
    "            if (np.amin(offset) < max_center_offset):\n",
    "                target.detected = True\n",
    "                target.lifetime += 1\n",
    "                target.LossCount = 0\n",
    "                target.ID = car_IDs[np.argmin(offset)]\n",
    "                \n",
    "                # If the running average is full, delete the last entry\n",
    "                if target.lifetime > max_frame_hist:\n",
    "                    del target.rec_bbox[0]\n",
    "\n",
    "                # Append the newest entry and calculate the new average position\n",
    "                target_bbox = np.asarray(bbox[np.argmin(offset)])\n",
    "                target.rec_bbox.append(target_bbox)\n",
    "                target.avg_bbox = (np.sum(np.stack(target.rec_bbox), axis = 0)/len(target.rec_bbox)).astype(int)\n",
    "                target.center = ((target.avg_bbox[0][0]+target.avg_bbox[1][0])/2,(target.avg_bbox[0][1]+target.avg_bbox[1][1])/2)\n",
    "            \n",
    "                car_IDs[np.argmin(offset)] = 99 # Set the ID to 99 to indicate it has been used this frame\n",
    "            \n",
    "    return car_IDs\n",
    "    \n",
    "def find_new_targets(bbox,bbox_center,car_IDs):\n",
    "    # Find bounding boxes for new targets\n",
    "    for target in targets:\n",
    "        if target.lifetime == 0:\n",
    "            #Start at the end of the list, which is the bottom of the frame\n",
    "            for car_number in car_IDs[::-1]:\n",
    "\n",
    "                #fix this next line, skipping lots of cars by only checking first labels\n",
    "                if car_number != 99:\n",
    "                    if target.lifetime == 0:\n",
    "                        target.detected = True\n",
    "                        target.lifetime += 1\n",
    "                        target.LossCount = 0\n",
    "                        target.ID = car_number\n",
    "                        target_bbox = np.asarray(bbox[car_number])\n",
    "                        target.rec_bbox = [target_bbox]\n",
    "                        target.avg_bbox = target_bbox\n",
    "                        target.center = ((target.avg_bbox[0][0]+target.avg_bbox[1][0])/2,(target.avg_bbox[0][1]+target.avg_bbox[1][1])/2)\n",
    "\n",
    "                        car_IDs[car_number] = 99 # Set the ID to 99 to indicate it has been used this frame\n",
    "    \n",
    "def draw_labeled_bboxes(img):\n",
    "    # Draw the bounding boxes for identified vehicles\n",
    "    for target in targets:\n",
    "        # If a car was not found, increment the loss counter\n",
    "        if not target.detected:\n",
    "            target.LossCount += 1\n",
    "            # If the target hasn't been seen within the max allowed frames, delete the target history\n",
    "            if target.LossCount > max_loss_count:\n",
    "                target.reset()                \n",
    "        if (target.lifetime >= min_lifetime):# and (target.ID is not None):\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, (target.avg_bbox[0][0],target.avg_bbox[0][1]),\n",
    "                          (target.avg_bbox[1][0], target.avg_bbox[1][1]), (0,0,255), 6)\n",
    "\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def pipeline(image, show_heat = False):\n",
    "    # Init variables for loop\n",
    "    for target in targets:\n",
    "        target.detected = False\n",
    "        \n",
    "    # Get the heatmap of the current frame\n",
    "    heatmap, labels, car_IDs = find_heatmap(image)\n",
    "    \n",
    "    # Correlate identified targets to vehicles\n",
    "    if len(car_IDs):\n",
    "        bbox, bbox_center = convert_heatmap_to_bbox(image,labels,car_IDs)\n",
    "        unused_car_IDs = find_existing_targets(bbox, bbox_center, car_IDs)\n",
    "        find_new_targets(bbox, bbox_center, unused_car_IDs)\n",
    "\n",
    "    # Draw the bounding boxes\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image))\n",
    "    \n",
    "    if show_heat:\n",
    "        return heatmap, draw_img\n",
    "    else:\n",
    "        return draw_img\n",
    "    \n",
    "class Vehicle():\n",
    "    def __init__(self):\n",
    "        self.detected = False # Was the vehicle detected this frame\n",
    "        self.ID = None # The ID of the vehicle (label number)\n",
    "        self.LossCount = 0 # Number of frames since the vehicle was last seen\n",
    "        self.lifetime = 0 # Number of frames that the vehicle has been seen\n",
    "        self.avg_bbox = [(None, None),(None, None)] # Average position over the last N frames\n",
    "        self.rec_bbox = [None] # History of last N positions\n",
    "        self.center = [None,None] # Centroid of current vehicle\n",
    "        \n",
    "    def reset(self):\n",
    "        self.detected = False # Was the vehicle detected this frame\n",
    "        self.ID = None # The ID of the vehicle (label number)\n",
    "        self.LossCount = 0 # Number of frames since the vehicle was last seen\n",
    "        self.lifetime = 0 # Number of frames that the vehicle has been seen\n",
    "        self.avg_bbox = [(None, None),(None, None)] # Average position over the last N frames\n",
    "        self.rec_bbox = [None] # History of last N positions\n",
    "        self.center = [None,None] # Centroid of current vehicle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pipeline on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## FRAME 1\n",
      "######################################## FRAME 2\n",
      "######################################## FRAME 3\n",
      "######################################## FRAME 4\n",
      "######################################## FRAME 5\n",
      "######################################## FRAME 6\n",
      "######################################## FRAME 7\n",
      "######################################## FRAME 8\n",
      "######################################## FRAME 9\n",
      "######################################## FRAME 10\n",
      "######################################## FRAME 11\n",
      "######################################## FRAME 12\n",
      "######################################## FRAME 13\n",
      "######################################## FRAME 14\n",
      "######################################## FRAME 15\n",
      "######################################## FRAME 16\n",
      "######################################## FRAME 17\n",
      "######################################## FRAME 18\n",
      "######################################## FRAME 19\n",
      "######################################## FRAME 20\n",
      "######################################## FRAME 21\n",
      "######################################## FRAME 22\n",
      "######################################## FRAME 23\n",
      "######################################## FRAME 24\n",
      "######################################## FRAME 25\n",
      "######################################## FRAME 26\n",
      "######################################## FRAME 27\n",
      "######################################## FRAME 28\n",
      "######################################## FRAME 29\n",
      "######################################## FRAME 30\n",
      "######################################## FRAME 31\n",
      "######################################## FRAME 32\n",
      "######################################## FRAME 33\n",
      "######################################## FRAME 34\n"
     ]
    }
   ],
   "source": [
    "svc_pickle = pickle.load( open(\"svc_pickle.pkl\", \"rb\" ) )\n",
    "svc = svc_pickle[\"svc\"]\n",
    "X_scaler = svc_pickle[\"X_scaler\"]\n",
    "\n",
    "# Create a list of vehicles for tracking\n",
    "targets = [Vehicle(),Vehicle(),Vehicle()]\n",
    "frame_count = 0\n",
    "fnames = glob.glob(\"test_video_frames/*.jpg\")\n",
    "plt.close()\n",
    "for fname in fnames:\n",
    "    frame_count += 1\n",
    "    print(\"######################################## FRAME {}\".format(frame_count))\n",
    "    image = mpimg.imread(fname)\n",
    "    heatmap, draw_img = pipeline(image, show_heat = True)\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Car Positions')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(heatmap, cmap='hot')\n",
    "    plt.title('Heat Map')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pipeline on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video_full_length_8.mp4\n",
      "[MoviePy] Writing video output_videos/project_video_full_length_8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [21:29<00:01,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/project_video_full_length_8.mp4 \n",
      "\n",
      "Wall time: 21min 31s\n"
     ]
    }
   ],
   "source": [
    "svc_pickle = pickle.load( open(\"svc_pickle.pkl\", \"rb\" ) )\n",
    "svc = svc_pickle[\"svc\"]\n",
    "X_scaler = svc_pickle[\"X_scaler\"]\n",
    "\n",
    "# Create a list of vehicles for tracking\n",
    "targets = [Vehicle(),Vehicle(),Vehicle()]\n",
    "\n",
    "# Choose the video file\n",
    "video = 'project_video'\n",
    "#video = 'test_video'\n",
    "length = '_full_length'\n",
    "#length = '_clipped'\n",
    "\n",
    "# Increment the video count\n",
    "count = 0\n",
    "file_list = glob.glob(\"output_videos/*.mp4\")\n",
    "for file in file_list:\n",
    "    if video+length in file:\n",
    "        count += 1\n",
    "\n",
    "output = 'output_videos/{}{}_{}.mp4'.format(video, length, count)\n",
    "\n",
    "if length == '_full_length':\n",
    "    clip1 = VideoFileClip(\"{}.mp4\".format(video))\n",
    "if length == '_clipped':\n",
    "    clip1 = VideoFileClip(\"{}.mp4\".format(video)).subclip(4,7)\n",
    "clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 6108\n",
      "5.4 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.989\n"
     ]
    }
   ],
   "source": [
    "# Read in cars and notcars\n",
    "car_images = glob.glob('vehicles/*/*.png')\n",
    "notcar_images = glob.glob('non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in car_images:\n",
    "    cars.append(image)\n",
    "for image in notcar_images:\n",
    "    notcars.append(image)\n",
    "\n",
    "# Reduce the sample size\n",
    "sample_size = 2000\n",
    "random.shuffle(cars)\n",
    "random.shuffle(notcars)\n",
    "sample_cars = cars[0:sample_size]\n",
    "sample_notcars = notcars[0:sample_size]\n",
    "\n",
    "train_cars = cars\n",
    "train_notcars = notcars\n",
    "\n",
    "car_features = extract_features(train_cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(train_notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "\n",
    "output = open('svc_pickle.pkl', 'wb')\n",
    "pickle.dump({\"svc\":svc,\"X_scaler\":X_scaler}, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in glob.glob(\"examples/color_spaces/*.png\"):\n",
    "    # Read a color image\n",
    "    img = cv2.imread(fname)\n",
    "\n",
    "    # Select a small fraction of pixels to plot by subsampling it\n",
    "    scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "    img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Convert subsampled image to desired color space(s)\n",
    "    img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "    img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "    img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "    img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "    # Plot and show\n",
    "    plot3d(img_small_RGB, img_small_rgb)\n",
    "    plt.show()\n",
    "    plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "    plt.show()\n",
    "    plot3d(img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Binning of Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an image\n",
    "# You can also read cutout2, 3, 4 etc. to see other examples\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "    \n",
    "feature_vec = bin_spatial(image, size=(32, 32))\n",
    "\n",
    "# Plot features\n",
    "plt.plot(feature_vec)\n",
    "plt.title('Spatially Binned Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-image HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cars and notcars\n",
    "car_images = glob.glob('vehicles/*/*.png')\n",
    "notcar_images = glob.glob('non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in car_images:\n",
    "    cars.append(image)\n",
    "for image in notcar_images:\n",
    "    notcars.append(image)\n",
    "        \n",
    "# Generate a random index to look at a car image\n",
    "ind = np.random.randint(0, len(cars))\n",
    "# Read in the image\n",
    "image = mpimg.imread(cars[ind])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# Define HOG parameters\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "# Call our function with vis=True to see an image output\n",
    "features, hog_image = get_hog_features(gray, orient, \n",
    "                        pix_per_cell, cell_per_block, \n",
    "                        vis=True, feature_vec=False)\n",
    "\n",
    "\n",
    "# Plot the examples\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Example Car Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(hog_image, cmap='gray')\n",
    "plt.title('HOG Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_video_frames/test_video_25.jpg')\n",
    "\n",
    "ystart = [400, 400, 400, 400]\n",
    "ystop = [464, 496, 512, 628]\n",
    "scale = [1.0, 1.5, 1.75, 2.0]\n",
    "window_img = np.copy(image)\n",
    "for search in zip(ystart, ystop, scale):\n",
    "\n",
    "    windows = slide_window(window_img, x_start_stop=(0, image.shape[1]), y_start_stop=(search[0], search[1]), \n",
    "                        xy_window=(int(search[2]*64), int(search[2]*64)), xy_overlap=(0.5, 0.5))                       \n",
    "    window_img = draw_boxes(window_img, windows, color=(0, 255, 255), thick=6)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hog Sub-sampling Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "bboxes = []\n",
    "ystart = [400, 400, 400, 400]\n",
    "ystop = [464, 496, 512, 628]\n",
    "scale = [1.0, 1.5, 1.75, 2.0]\n",
    "\n",
    "for search in zip(ystart, ystop, scale):\n",
    "    temp_bboxes = find_cars(img, search[0], search[1], search[2], svc, X_scaler, color_space, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    bboxes += temp_bboxes\n",
    "out_img = draw_boxes(img, bboxes)\n",
    "plt.imshow(out_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Detections and False-Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "draw_labeled_bboxes() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3bf40eff172c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Find final boxes from heatmap using label function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdraw_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_labeled_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: draw_labeled_bboxes() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Read in a pickle file with bboxes saved\n",
    "# Each item in the \"all_bboxes\" list will contain a \n",
    "# list of boxes for one of the images shown above\n",
    "box_list = bboxes\n",
    "\n",
    "# Read in image similar to one shown above \n",
    "image = mpimg.imread('test_images/test5.jpg')\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "# Add heat to each box in box list\n",
    "heat = add_heat(heat,box_list)\n",
    "    \n",
    "# Apply threshold to help remove false positives\n",
    "heat = apply_threshold(heat,2)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "labels = label(heatmap)\n",
    "draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame grabber by Tobi Lehman\n",
    "https://tobilehman.com/blog/2013/01/20/extract-array-of-frames-from-mp4-using-python-opencv-bindings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test_video.mp4'\n",
    "vidcap = cv2.VideoCapture(fname)\n",
    "#The easiest way to extract frames is to use the read() method on the vidcap object.\n",
    "#It returns a tuple where the first element is a success flag and the second is the image array.\n",
    "#To extract the image array:\n",
    "success,image = vidcap.read()\n",
    "# image is an array of array of [R,G,B] values\n",
    "#To convert the whole video to frames and save each one:\n",
    "count = 0; \n",
    "frames = 2000\n",
    "while success:\n",
    "    success,image = vidcap.read()\n",
    "    cv2.imwrite(\"test_video_frames/{}_{}.jpg\".format(fname[:-4], count), image)\n",
    "    if count == frames:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
